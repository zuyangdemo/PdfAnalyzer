import streamlit as st
import os

from langchain.memory import ConversationBufferMemory
from utils import generate_result

st.title('PDF Assistant ğŸ’¡')

with st.sidebar:
    openai_api_key = st.text_input("è¯·è¾“å…¥OPENAI API å¯†é’¥", type="password", value=os.getenv("OPENAI_API_KEY"))
    st.markdown("[è·å–OPENAI API KEY å¯†é’¥](https://openai.com/)")

pdf_file = st.file_uploader(label="è¯·ä¸Šä¼ çš„ä½ çš„PDFæ–‡ä»¶", type="pdf")

question = st.text_input(label="è¯·è¾“å…¥ä½ çš„é—®é¢˜", disabled=not pdf_file)

if "memory" not in st.session_state:
    st.session_state['memory'] = ConversationBufferMemory(
        return_messages=True,
        memory_key="chat_history",
        output_key="answer"
    )

if pdf_file and question and not openai_api_key:
    st.info("è¯·è¾“å…¥OPENAI API KEY")
    st.stop()

if pdf_file and question and openai_api_key:
    with st.spinner("AI æ­£åœ¨æ£€ç´¢PDFæ–‡ä»¶ï¼Œè¯·ç¨å..."):
        response = generate_result(question=question,
                                   memory=st.session_state["memory"],
                                   openai_api_key=openai_api_key,
                                   file_docs=pdf_file)
        st.markdown("#### ç­”æ¡ˆ")
        st.write(response['answer'])
        st.session_state['chat_history'] = response['chat_history']

if "chat_history" in st.session_state:
    with st.expander(label="æŸ¥çœ‹å†å²ä¿¡æ¯"):
        for i in range(0, len(st.session_state['chat_history']), 2):
            human_history = st.session_state['chat_history'][i]
            ai_history = st.session_state['chat_history'][i + 1]
            st.write(human_history.content)
            st.write(ai_history.content)
            if i < len(st.session_state['chat_history']) - 2:
                st.divider()

